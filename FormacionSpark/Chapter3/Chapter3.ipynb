{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a40205bb-89c7-4431-8ee8-e4a164bd10ef",
   "metadata": {},
   "source": [
    "# Capítulo 3 Learning Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f3eca9-9274-4c73-888e-584759b7d223",
   "metadata": {},
   "source": [
    "## Alto nivel vs Bajo Nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "af2f309c-b054-4b9e-89aa-20ba9b572ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res128: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@3d671bd\n"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "fb9cabbe-2827-40d9-86e2-43f58eae1e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res129: org.apache.spark.SparkContext = org.apache.spark.SparkContext@1facc93c\n"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "076bd09c-12b2-4832-8672-7d190653dbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Importamos las funciones\n",
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f86d2c-3746-478f-b61d-8c21f48d13c0",
   "metadata": {},
   "source": [
    "### Creación de DataFrame por secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7d386dff-51ac-4514-8204-5d7e752f1b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [Nombre: string, Edad: int]\n"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.createDataFrame(Seq((\"Brooke\",20),(\"Denny\",31),(\"Jules\",30),(\"TD\",35),(\"Brooke\",35))).toDF(\"Nombre\",\"Edad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9150e730-3ea1-4ad2-9590-058dbacec8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+\n",
      "|Nombre|Edad|\n",
      "+------+----+\n",
      "|Brooke|  20|\n",
      "| Denny|  31|\n",
      "| Jules|  30|\n",
      "|    TD|  35|\n",
      "|Brooke|  35|\n",
      "+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb82387-690d-4ca2-a00a-4f71a800695a",
   "metadata": {},
   "source": [
    "### Ejemplos de qué se puede hacer en Alto Nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "30aae864-fbf0-45bf-9a8a-025be19080f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfmedia: org.apache.spark.sql.DataFrame = [Nombre: string, Media: double]\n"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfmedia = df.groupBy(\"Nombre\").agg(avg(\"Edad\").alias(\"Media\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4c6a6fe9-e728-460c-902d-531e47fcb422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Nombre|Media|\n",
      "+------+-----+\n",
      "|Brooke| 27.5|\n",
      "| Denny| 31.0|\n",
      "| Jules| 30.0|\n",
      "|    TD| 35.0|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfmedia.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e7e79a-71c8-49ac-8027-bacb3f634276",
   "metadata": {},
   "source": [
    "## Tipos de datos en SPARK de Scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "63cc33fc-07f3-4fdb-ac9c-2c71a055c1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types._\n"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// importamos los tipos de datos\n",
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "95f0331c-5e02-43bf-a0ec-7a556d64952e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nameTypes: org.apache.spark.sql.types.StringType.type = StringType\n"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val nameTypes = StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5a0097e9-e34d-4867-9c67-4be7d8d2184d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "firsName: org.apache.spark.sql.types.StringType.type = StringType\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val firsName = nameTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "7cc1a711-7401-4d55-9b65-2ee03759c99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastName: org.apache.spark.sql.types.StringType.type = StringType\n"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lastName = nameTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea228f70-6415-4103-9d07-04ed434c804a",
   "metadata": {},
   "source": [
    "## Definimos un SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "470ee805-9506-4324-ba9b-1ea58cad28b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(Autor,StringType,false), StructField(Titulo,StringType,false), StructField(Pagina,IntegerType,false))\n"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// FORMA PROGRAMATIVA\n",
    "val schema = StructType(\n",
    "    Array(\n",
    "    StructField(\"Autor\",StringType,false), //Creo que el falso indica si puede o no ser nulo\n",
    "    StructField(\"Titulo\",StringType,false),\n",
    "    StructField(\"Pagina\",IntegerType,false)\n",
    "    )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2481e0e3-9cd6-49db-8a3a-daeabff0ea40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema2: String = autor STRING, titulo STRING, paginas INT\n"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// FORMA FACIL (DDL)\n",
    "val schema2 = \"autor STRING, titulo STRING, paginas INT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b12617ee-aa64-49ae-bca5-2ffa4bdfcf82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(author,StringType,false), StructField(title,StringType,true), StructField(pages,IntegerType,false))\n"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val schema = StructType(Array(StructField(\"author\", StringType, false),\n",
    "    StructField(\"title\", StringType, true),\n",
    "    StructField(\"pages\", IntegerType, false)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2b783d-0c26-4336-a8a1-053bae996551",
   "metadata": {},
   "source": [
    "## Ejemplo de uso de SCHEMA y lectura de JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44f61e8-d9ea-4901-86de-5f617b5ab430",
   "metadata": {},
   "source": [
    "### Sin SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "0a015581-bd33-4a59-aeab-407c8b311d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jsonfile: org.apache.spark.sql.DataFrame = [Campaigns: array<string>, First: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// cargamos el arvhivo JSON\n",
    "val jsonfile = spark.read.format(\"json\")\n",
    "    .load(\"blogs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "64c9d076-1312-44fd-8b96-064e99ab5afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----+---+-------+---------+-----------------+\n",
      "|           Campaigns|    First| Hits| Id|   Last|Published|              Url|\n",
      "+--------------------+---------+-----+---+-------+---------+-----------------+\n",
      "| [twitter, LinkedIn]|    Jules| 4535|  1|  Damji| 1/4/2016|https://tinyurl.1|\n",
      "| [twitter, LinkedIn]|   Brooke| 8908|  2|  Wenig| 5/5/2018|https://tinyurl.2|\n",
      "|[web, twitter, FB...|    Denny| 7659|  3|    Lee| 6/7/2019|https://tinyurl.3|\n",
      "|       [twitter, FB]|Tathagata|10568|  4|    Das|5/12/2018|https://tinyurl.4|\n",
      "|[web, twitter, FB...|    Matei|40578|  5|Zaharia|5/14/2014|https://tinyurl.5|\n",
      "+--------------------+---------+-----+---+-------+---------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonfile.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb05979f-1dab-4055-8a61-5d1af818ea8f",
   "metadata": {},
   "source": [
    "### Con SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a66d7df8-db32-43f8-8ff0-fd188c196ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(Id,IntegerType,false), StructField(First,StringType,false), StructField(Last,StringType,false), StructField(Url,StringType,false), StructField(Published,DateType,false), StructField(Hits,IntegerType,false), StructField(Campaigns,ArrayType(StringType,true),false))\n"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// CREO MI SCHEMA\n",
    "val schema = StructType(\n",
    "    Array(\n",
    "    StructField(\"Id\",IntegerType,false), //Creo que el falso indica si puede o no ser nulo\n",
    "    StructField(\"First\",StringType,false),\n",
    "    StructField(\"Last\",StringType,false),\n",
    "    StructField(\"Url\",StringType,false),\n",
    "    StructField(\"Published\",DateType,false),\n",
    "    StructField(\"Hits\",IntegerType,false),\n",
    "    StructField(\"Campaigns\",ArrayType(StringType),false)\n",
    "    )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1b315481-0eb7-4a7e-9145-5a674770388d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfBlog: org.apache.spark.sql.DataFrame = [Id: int, First: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfBlog = spark.read.schema(schema).json(\"blogs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "67280141-1edc-49d7-98ae-801b82bf8691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+----------------------------+\n",
      "|Id |First    |Last   |Url              |Published|Hits |Campaigns                   |\n",
      "+---+---------+-------+-----------------+---------+-----+----------------------------+\n",
      "|1  |Jules    |Damji  |https://tinyurl.1|null     |4535 |[twitter, LinkedIn]         |\n",
      "|2  |Brooke   |Wenig  |https://tinyurl.2|null     |8908 |[twitter, LinkedIn]         |\n",
      "|3  |Denny    |Lee    |https://tinyurl.3|null     |7659 |[web, twitter, FB, LinkedIn]|\n",
      "|4  |Tathagata|Das    |https://tinyurl.4|null     |10568|[twitter, FB]               |\n",
      "|5  |Matei    |Zaharia|https://tinyurl.5|null     |40578|[web, twitter, FB, LinkedIn]|\n",
      "|6  |Reynold  |Xin    |https://tinyurl.6|null     |25568|[twitter, LinkedIn]         |\n",
      "+---+---------+-------+-----------------+---------+-----+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfBlog.show(truncate = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "62f4e8d6-106a-4e4e-b1aa-654c21a08962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- First: string (nullable = true)\n",
      " |-- Last: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Published: date (nullable = true)\n",
      " |-- Hits: integer (nullable = true)\n",
      " |-- Campaigns: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfBlog.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a7f30a-eda0-413f-858a-7a82bca2bf16",
   "metadata": {},
   "source": [
    "## Columns & Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c127a325-43be-4f41-94a9-dec747a808e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res135: Array[String] = Array(Id, First, Last, Url, Published, Hits, Campaigns)\n"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Vamos a ver las columnas del dataFrame anterior\n",
    "dfBlog.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "abdd27bd-55e9-4bcb-896a-d3e9526ab31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- First: string (nullable = true)\n",
      " |-- Last: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Published: date (nullable = true)\n",
      " |-- Hits: integer (nullable = true)\n",
      " |-- Campaigns: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfBlog.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "dcf80d83-4057-44ae-a6a4-2d4ddcb4891a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res137: org.apache.spark.sql.Column = Id\n"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBlog.col(\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "5a300b41-d7dd-44e8-9673-be2f826d02ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|(Hits * 2)|\n",
      "+----------+\n",
      "|      9070|\n",
      "|     17816|\n",
      "|     15318|\n",
      "|     21136|\n",
      "|     81156|\n",
      "|     51136|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Vamos a utilizar expr para multiplicar\n",
    "dfBlog.select(expr(\"Hits*2\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "9013e607-688f-488a-92f7-9e278508d908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|(Hits * 2)|\n",
      "+----------+\n",
      "|      9070|\n",
      "|     17816|\n",
      "|     15318|\n",
      "|     21136|\n",
      "|     81156|\n",
      "|     51136|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Equivalentemente\n",
    "dfBlog.select($\"Hits\"*2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "3fbaf0e9-430e-46a3-b904-93c4b3105405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|(Hits * 2)|\n",
      "+----------+\n",
      "|      9070|\n",
      "|     17816|\n",
      "|     15318|\n",
      "|     21136|\n",
      "|     81156|\n",
      "|     51136|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// USAR $\"...\" es lo mismo que col(\"...\")\n",
    "dfBlog.select(col(\"Hits\")*2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61756c26-93c1-4d86-bf28-35ad979a91b8",
   "metadata": {},
   "source": [
    "### Intentamos multiplicar una String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9ea76fc6-4050-4e4a-8e7d-0c89b945cfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|(Last * 2)|\n",
      "+----------+\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfBlog.select(col(\"Last\")*2).show()\n",
    "// devuelve nulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "15f1e477-2df9-4826-91d2-d117bbf017ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|(Last * 2)|\n",
      "+----------+\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfBlog.select(expr(\"Last*2\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471cde1c-fcf3-4d27-8f2e-6092f7393bee",
   "metadata": {},
   "source": [
    "## Renombrar columnas de un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "10769cd6-7e16-41e1-a1d9-3d1fcecbec28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- First: string (nullable = true)\n",
      " |-- Apellido: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Published: date (nullable = true)\n",
      " |-- Hits: integer (nullable = true)\n",
      " |-- Campaigns: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df1: org.apache.spark.sql.DataFrame = [Id: int, First: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df1 = dfBlog.withColumnRenamed(\"Last\",\"Apellido\")\n",
    "df1.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a17b39b-6c58-4253-97ef-793a069ede15",
   "metadata": {},
   "source": [
    "### Usar expresiones para condiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "b0059b0d-be28-4ad1-81a6-71ab56e39503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+---------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|NombreCol|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+---------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1|     null| 4535| [twitter, LinkedIn]|    false|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2|     null| 8908| [twitter, LinkedIn]|    false|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3|     null| 7659|[web, twitter, FB...|    false|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|     null|10568|       [twitter, FB]|     true|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|     null|40578|[web, twitter, FB...|     true|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6|     null|25568| [twitter, LinkedIn]|     true|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfBlog.withColumn(\"NombreCol\", expr(\"Hits > 10000\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267fd25d-6ca3-4d4a-857e-6a9b2d13f22d",
   "metadata": {},
   "source": [
    "### Concatenar columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "eee94d34-ec19-40ca-89e6-17850130af3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+-------------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|Concatenacion|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-------------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1|     null| 4535| [twitter, LinkedIn]|   JulesDamji|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2|     null| 8908| [twitter, LinkedIn]|  BrookeWenig|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3|     null| 7659|[web, twitter, FB...|     DennyLee|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|     null|10568|       [twitter, FB]| TathagataDas|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|     null|40578|[web, twitter, FB...| MateiZaharia|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6|     null|25568| [twitter, LinkedIn]|   ReynoldXin|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-------------+\n",
      "\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-------------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|Concatenacion|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-------------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1|     null| 4535| [twitter, LinkedIn]|   JulesDamji|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2|     null| 8908| [twitter, LinkedIn]|  BrookeWenig|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3|     null| 7659|[web, twitter, FB...|     DennyLee|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|     null|10568|       [twitter, FB]| TathagataDas|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|     null|40578|[web, twitter, FB...| MateiZaharia|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6|     null|25568| [twitter, LinkedIn]|   ReynoldXin|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfBlog.withColumn(\"Concatenacion\",concat($\"First\",$\"Last\")).show()\n",
    "dfBlog.withColumn(\"Concatenacion\",concat(expr(\"First\"),expr(\"Last\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed26f255-3416-4258-bc1c-19014e196d53",
   "metadata": {},
   "source": [
    "### Similitud entre métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "d69d11f3-5a50-4cf6-bbaf-96a6af9059d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|Hits|\n",
      "+----+\n",
      "|4535|\n",
      "|8908|\n",
      "+----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----+\n",
      "|Hits|\n",
      "+----+\n",
      "|4535|\n",
      "|8908|\n",
      "+----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----+\n",
      "|Hits|\n",
      "+----+\n",
      "|4535|\n",
      "|8908|\n",
      "+----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----+\n",
      "|Hits|\n",
      "+----+\n",
      "|4535|\n",
      "|8908|\n",
      "+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfBlog.select(\"Hits\").show(2)\n",
    "dfBlog.select(col(\"Hits\")).show(2)\n",
    "dfBlog.select(expr(\"Hits\")).show(2)\n",
    "dfBlog.select($\"Hits\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c9613b-2efb-4368-ae9e-b4a689dc8a9e",
   "metadata": {},
   "source": [
    "## Cómo ordenar un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "fba95cb9-8216-4218-9ef5-4e14236ab4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6|     null|25568| [twitter, LinkedIn]|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|     null|40578|[web, twitter, FB...|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|     null|10568|       [twitter, FB]|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3|     null| 7659|[web, twitter, FB...|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2|     null| 8908| [twitter, LinkedIn]|\n",
      "|  1|    Jules|  Damji|https://tinyurl.1|     null| 4535| [twitter, LinkedIn]|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfBlog.sort($\"Id\".desc).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a7a34d-b96f-4305-829c-a79fd156a72d",
   "metadata": {},
   "source": [
    "## OBJETO FILAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8f164cf6-0645-4e26-a0c0-94e4838e4ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.Row\n"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// importamos el objeto Row\n",
    "import org.apache.spark.sql.Row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec190b3d-de54-4d7e-b402-431ee6fd1625",
   "metadata": {},
   "source": [
    "### Acceso por indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "1ad514b5-2d5e-4f13-b756-80a96a827470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filablog: org.apache.spark.sql.Row = [6,Reynold,Xin,https//tinyurl.6,255568,3/2/2015,[Ljava.lang.String;@56bc2f2a]\n"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// creamos una fila\n",
    "val filablog = Row(6,\"Reynold\",\"Xin\",\"https//tinyurl.6\",255568,\"3/2/2015\",Array(\"twitter\",\"LinkedIn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "27aef0ec-9540-4ee1-bd17-da11652389f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res148: Any = Reynold\n"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// acedemos por indice \n",
    "filablog(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "5cfafb0e-f514-46df-a28e-2b6eaf99dcda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filablog2: org.apache.spark.sql.Row = [5,agatha,christie,https//youtube.com,777,31/3/2012,[Ljava.lang.String;@7d89517b]\n"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val filablog2 = Row(5,\"agatha\",\"christie\",\"https//youtube.com\",777,\"31/3/2012\",Array(\"Instagram\",\"LinkedIn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a53877dd-b19d-4e35-a10a-9a1194874b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rows2: Seq[org.apache.spark.sql.Row] = List([6,Reynold,Xin,https//tinyurl.6,255568,3/2/2015,[Ljava.lang.String;@56bc2f2a], [5,agatha,christie,https//youtube.com,777,31/3/2012,[Ljava.lang.String;@7d89517b])\n"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rows2 = Seq(filablog,filablog2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "93bbc3cd-0f9e-46a4-907c-81ed26f0bd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "// ESTA ME DA ERROR\n",
    "//val df2 = spark.createDataFrameto(rows2).toDF(\"Id\",\"Nombre\",\"Apellido\",\"url\",\"Numero\",\"Fecha\",\"redes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b077656c-7a3f-446f-ab29-96d9ffd71489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|       Author|State|\n",
      "+-------------+-----+\n",
      "|Matei Zaharia|   CA|\n",
      "|  Reynold Xin|   CA|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rows: Seq[(String, String)] = List((Matei Zaharia,CA), (Reynold Xin,CA))\n",
       "authorsDF: org.apache.spark.sql.DataFrame = [Author: string, State: string]\n"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rows = Seq((\"Matei Zaharia\", \"CA\"), (\"Reynold Xin\", \"CA\"))\n",
    "val authorsDF = rows.toDF(\"Author\", \"State\")\n",
    "authorsDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d3636-8f55-4934-950a-75fdee01bacc",
   "metadata": {},
   "source": [
    "## DataFrame Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f01d630-f892-42fc-9c0e-1130ab9b653e",
   "metadata": {},
   "source": [
    "### Lectura de DataFrames (DataFrameReader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "036bb8aa-ea5a-4a1d-b1cc-40d3eefa8c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sampleDF: org.apache.spark.sql.DataFrame = [CallNumber: string, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// VAMOS A LEER UNOS POCOS DATOS PARA VER QuE ESTRucturA tienen\n",
    "val sampleDF = spark.read\n",
    "                    .option(\"samplingRatio\",0.001)\n",
    "                    .option(\"header\",true)\n",
    "                    .csv(\"sf-fire-calls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f7b4a84f-0cab-4120-bcb8-3d252bd494e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+--------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+---------------+--------------------+-------------+-----+\n",
      "|CallNumber|UnitID|IncidentNumber|      CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|   Neighborhood|            Location|        RowID|Delay|\n",
      "+----------+------+--------------+--------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+---------------+--------------------+-------------+-----+\n",
      "|  20110016|   T13|       2003235|Structure Fire|01/11/2002|01/10/2002|               Other|01/11/2002 01:51:...|2000 Block of CAL...|  SF|  94109|      B04|         38|3362|               3|       3|            3|  false|         null|        1|   TRUCK|                         2|                     4|                 5|Pacific Heights|(37.7895840679362...|020110016-T13| 2.95|\n",
      "+----------+------+--------------+--------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+---------------+--------------------+-------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampleDF.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "3be1fa71-1b10-4019-9522-ce98b9592e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res152: Array[String] = Array(CallNumber, UnitID, IncidentNumber, CallType, CallDate, WatchDate, CallFinalDisposition, AvailableDtTm, Address, City, Zipcode, Battalion, StationArea, Box, OriginalPriority, Priority, FinalPriority, ALSUnit, CallTypeGroup, NumAlarms, UnitType, UnitSequenceInCallDispatch, FirePreventionDistrict, SupervisorDistrict, Neighborhood, Location, RowID, Delay)\n"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleDF.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4550c15-5936-4ade-aff2-4bfceab6e5af",
   "metadata": {},
   "source": [
    "### Creación del Schema para el dataFRame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f476f229-0664-46c2-b898-cb73bde32b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fire_schema: org.apache.spark.sql.types.StructType = StructType(StructField(CallNumber,IntegerType,true), StructField(UnitID,StringType,true), StructField(IncidentNumber,IntegerType,true), StructField(CallType,StringType,true), StructField(CallDate,StringType,true), StructField(WatchDate,StringType,true), StructField(CallFinalDisposition,StringType,true), StructField(AvailableDtTm,StringType,true), StructField(Address,StringType,true), StructField(City,StringType,true), StructField(Zipcode,IntegerType,true), StructField(Battalion,StringType,true), StructField(StationArea,IntegerType,true), StructField(Box,IntegerType,true), StructField(OriginalPriority,IntegerType,true), StructField(Priority,IntegerType,true), StructField(FinalPriority,IntegerType,true), StructField(ALSUnit,BooleanType,...\n"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fire_schema = StructType(Array(\n",
    "    StructField(\"CallNumber\", IntegerType,true),\n",
    "    StructField(\"UnitID\", StringType, true),\n",
    "    StructField(\"IncidentNumber\", IntegerType, true),\n",
    "    StructField(\"CallType\", StringType, true),\n",
    "    StructField(\"CallDate\", StringType, true),\n",
    "    StructField(\"WatchDate\", StringType, true),\n",
    "    StructField(\"CallFinalDisposition\", StringType, true),\n",
    "    StructField(\"AvailableDtTm\", StringType, true),\n",
    "    StructField(\"Address\", StringType, true),\n",
    "    StructField(\"City\", StringType, true),\n",
    "    StructField(\"Zipcode\", IntegerType, true),\n",
    "    StructField(\"Battalion\", StringType, true),\n",
    "    StructField(\"StationArea\", IntegerType, true),\n",
    "    StructField(\"Box\", IntegerType, true),\n",
    "    StructField(\"OriginalPriority\", IntegerType, true),\n",
    "    StructField(\"Priority\", IntegerType, true),\n",
    "    StructField(\"FinalPriority\", IntegerType, true),\n",
    "    StructField(\"ALSUnit\", BooleanType, true),\n",
    "    StructField(\"CallTypeGroup\", StringType, true),\n",
    "    StructField(\"NumAlarms\", IntegerType, true),\n",
    "    StructField(\"UnitType\", StringType, true),\n",
    "    StructField(\"UnitSequenceInCallDispatch\", IntegerType, true),\n",
    "    StructField(\"FirePreventionDistrict\", IntegerType, true),\n",
    "    StructField(\"SupervisorDistrict\", IntegerType, true),\n",
    "    StructField(\"Neighborhood\", StringType, true),\n",
    "    StructField(\"Location\",StringType,true),\n",
    "    StructField(\"RowID\", StringType, true),\n",
    "    StructField(\"Delay\", FloatType, true)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "4787e764-555c-44eb-9d78-6729246f8dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fire_df: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fire_df = spark.read.schema(fire_schema)\n",
    "                        .option(\"header\",true)\n",
    "                        .option(\"sep\",\",\")\n",
    "                        .csv(\"sf-fire-calls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "39640dcc-8eb8-4bd9-a412-9421f8187cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+-----+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+-----+\n",
      "|  20110016|   T13|       2003235|  Structure Fire|01/11/2002|01/10/2002|               Other|01/11/2002 01:51:...|2000 Block of CAL...|  SF|  94109|      B04|         38|3362|               3|       3|            3|  false|         null|        1|   TRUCK|                         2|                     4|                 5|     Pacific Heights|(37.7895840679362...|020110016-T13| 2.95|\n",
      "|  20110022|   M17|       2003241|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 03:01:...|0 Block of SILVER...|  SF|  94124|      B10|         42|6495|               3|       3|            3|   true|         null|        1|   MEDIC|                         1|                    10|                10|Bayview Hunters P...|(37.7337623673897...|020110022-M17|  4.7|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46a1cbb-8e6c-430f-b1f2-168b34bd0312",
   "metadata": {},
   "source": [
    "## Guardar un DataFrame formato Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a2aa6cfb-857e-4c63-af40-3dbf68562135",
   "metadata": {},
   "outputs": [],
   "source": [
    "// PARA NO GUARDARLA OTRA VEZ SE HA COMENTADO\n",
    "//fire_df.write.format(\"parquet\").save(\"parquetEjemplo2forma2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67509deb-3be4-418c-b96e-80b4594c24d1",
   "metadata": {},
   "source": [
    "## Guardar DataFrame formato TABLA SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "588de177-7b99-41ba-b122-9076629200b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "// PARA NO GUARDARLA AGAIN SE HA COMENTADO\n",
    "//fire_df.write.format(\"parquet\").saveAsTable(\"parquetTable2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e5833a-c2be-4250-9743-12f107790ced",
   "metadata": {},
   "source": [
    "## Ejecutamos Transformaciones y Acciones del capitulo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "346cb49f-9265-42e6-8002-3657569a8dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res156: org.apache.spark.sql.Row = [20110016,T13,2003235,Structure Fire,01/11/2002,01/10/2002,Other,01/11/2002 01:51:44 AM,2000 Block of CALIFORNIA ST,SF,94109,B04,38,3362,3,3,3,false,null,1,TRUCK,2,4,5,Pacific Heights,(37.7895840679362, -122.428071912459),020110016-T13,2.95]\n"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "5bdb4d98-bd36-4130-9683-ad287f6ad3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res157: Long = 175296\n"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "6ae216ac-ad9b-4711-9a1f-ed531b3c0d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agreg: org.apache.spark.sql.DataFrame = [CallDate: string, count: bigint]\n"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val agreg = fire_df.groupBy(\"CallDate\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "5612ed05-243c-415e-bb16-e5779c98b2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res158: Long = 6783\n"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreg.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da980ae8-05a2-4fde-9663-d832d7ddfae7",
   "metadata": {},
   "source": [
    "## Proyecciones y filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "0f6deec2-d93a-43e2-b400-28b7bbecbf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+----------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType        |\n",
      "+--------------+----------------------+----------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|Structure Fire  |\n",
      "|2003241       |01/11/2002 03:01:18 AM|Medical Incident|\n",
      "|2003242       |01/11/2002 02:39:50 AM|Medical Incident|\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms          |\n",
      "|2003279       |01/11/2002 08:03:26 AM|Structure Fire  |\n",
      "+--------------+----------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fewFireDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [IncidentNumber: int, AvailableDtTm: string ... 1 more field]\n"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fewFireDF = fire_df.select(\"IncidentNumber\",\"AvailableDtTm\",\"CallType\").where($\"CallType\" =!= \"Vehicle Fire\")\n",
    "fewFireDF.show(5,truncate=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef6930a-b8d9-446b-82e7-8fabd154fe2c",
   "metadata": {},
   "source": [
    "## Distinct en Spark SCALA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ee6963d1-5ca1-483f-b12c-4c0ebacc4395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "565e25a1-4a98-4d41-87d0-baa82a0002cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|DistintosTypos|\n",
      "+--------------+\n",
      "|            30|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.select(\"CallType\")\n",
    "    .where($\"CallType\".isNotNull)\n",
    "    .agg(countDistinct(\"CallType\").as(\"DistintosTypos\"))\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "b5b4f8c1-3cea-46a8-9920-ac0f8ea2a3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|CallType                     |\n",
      "+-----------------------------+\n",
      "|Elevator / Escalator Rescue  |\n",
      "|Marine Fire                  |\n",
      "|Aircraft Emergency           |\n",
      "|Administrative               |\n",
      "|Alarms                       |\n",
      "|Odor (Strange / Unknown)     |\n",
      "|Citizen Assist / Service Call|\n",
      "|HazMat                       |\n",
      "|Watercraft in Distress       |\n",
      "|Explosion                    |\n",
      "+-----------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.select(\"CallType\")\n",
    "    .where(col(\"CallType\").isNotNull)\n",
    "    .distinct()\n",
    "    .show(10,false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73113e1b-894c-4994-b76e-450f7ad111cd",
   "metadata": {},
   "source": [
    "## Cambiar el nombre, añadir y eliminar columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "ea435248-a9ad-454b-931f-cfef88b6a17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newdf: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val newdf = fire_df.withColumnRenamed(\"Delay\",\"Tolay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "2a4c4498-e916-4a84-9834-0ab32229a83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: integer (nullable = true)\n",
      " |-- Box: integer (nullable = true)\n",
      " |-- OriginalPriority: integer (nullable = true)\n",
      " |-- Priority: integer (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: integer (nullable = true)\n",
      " |-- SupervisorDistrict: integer (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Tolay: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "7e8ed90f-023a-4d51-a4be-c5a12a7d5dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|Tolay    |\n",
      "+---------+\n",
      "|5.35     |\n",
      "|6.25     |\n",
      "|5.2      |\n",
      "|5.6      |\n",
      "|7.25     |\n",
      "|11.916667|\n",
      "|5.116667 |\n",
      "|8.633333 |\n",
      "|95.28333 |\n",
      "|5.45     |\n",
      "+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf.select(\"Tolay\").where($\"Tolay\">5.0).show(10,false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b6d948-9ec9-47c4-bd3c-5795f27589cf",
   "metadata": {},
   "source": [
    "### Cambiar de String a Fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "4dfd8a96-a472-485c-95dc-b907d09f3402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res164: Array[String] = Array(CallNumber, UnitID, IncidentNumber, CallType, CallDate, WatchDate, CallFinalDisposition, AvailableDtTm, Address, City, Zipcode, Battalion, StationArea, Box, OriginalPriority, Priority, FinalPriority, ALSUnit, CallTypeGroup, NumAlarms, UnitType, UnitSequenceInCallDispatch, FirePreventionDistrict, SupervisorDistrict, Neighborhood, Location, RowID, Tolay)\n"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "fadd3f92-6b0e-4ee3-b9f2-667d5868178b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------------------+\n",
      "|CallDate  |WatchDate |AvailableDtTm         |\n",
      "+----------+----------+----------------------+\n",
      "|01/11/2002|01/10/2002|01/11/2002 01:51:44 AM|\n",
      "|01/11/2002|01/10/2002|01/11/2002 03:01:18 AM|\n",
      "|01/11/2002|01/10/2002|01/11/2002 02:39:50 AM|\n",
      "|01/11/2002|01/10/2002|01/11/2002 04:16:46 AM|\n",
      "|01/11/2002|01/10/2002|01/11/2002 06:01:58 AM|\n",
      "+----------+----------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf.select(\"CallDate\",\"WatchDate\",\"AvailableDtTm\").show(5,truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "b921d2ca-f88a-4f2a-a963-337bbb96a01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df3: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df3 = newdf.withColumn(\"FechaIncidente\",to_timestamp($\"CallDate\",\"MM/dd/yyyy\")).drop(\"CallDate\")\n",
    "               .withColumn(\"FechaVista\",to_timestamp($\"WatchDate\",\"MM/dd/yyyy\")).drop(\"WatchDate\")\n",
    "               .withColumn(\"Dateee\",to_timestamp($\"AvailableDtTm\",\"MM/dd/yyyy hh:mm:ss a\")).drop(\"AvailableDtTm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "49bcb7c2-9f4f-44bd-9767-24f04fd31389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+\n",
      "|     FechaIncidente|         FechaVista|             Dateee|\n",
      "+-------------------+-------------------+-------------------+\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 01:51:44|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 03:01:18|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.select(\"FechaIncidente\",\"FechaVista\",\"Dateee\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8738f9-36d5-401d-92e8-b56b3e0077bc",
   "metadata": {},
   "source": [
    "### Utilizar funciones Tiempo (día, mes o año)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "c0098e88-dd02-48ed-ab8c-459ae015d7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "ab1a811e-5a40-440d-b305-155a240784c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|year(FechaIncidente)|\n",
      "+--------------------+\n",
      "|                2002|\n",
      "|                2002|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---+\n",
      "|mes|\n",
      "+---+\n",
      "|  1|\n",
      "|  1|\n",
      "+---+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------------------------+\n",
      "|dayofmonth(FechaIncidente)|\n",
      "+--------------------------+\n",
      "|                        11|\n",
      "|                        11|\n",
      "+--------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.select(year($\"FechaIncidente\")).show(2);\n",
    "df3.select(month($\"FechaIncidente\")).withColumnRenamed(\"month(FechaIncidente)\",\"mes\").show(2);\n",
    "df3.select(dayofmonth($\"FechaIncidente\")).show(2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf3584f-8e23-4178-88ae-affd79c92d28",
   "metadata": {},
   "source": [
    "## Agregaciones y agrupaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a6cc806d-7316-45c6-a417-e107ad33f013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res168: Array[String] = Array(CallNumber, UnitID, IncidentNumber, CallType, CallFinalDisposition, Address, City, Zipcode, Battalion, StationArea, Box, OriginalPriority, Priority, FinalPriority, ALSUnit, CallTypeGroup, NumAlarms, UnitType, UnitSequenceInCallDispatch, FirePreventionDistrict, SupervisorDistrict, Neighborhood, Location, RowID, Tolay, FechaIncidente, FechaVista, Dateee)\n"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e8483243-d7c9-4401-a57c-2cc7fc490a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            CallType| count|\n",
      "+--------------------+------+\n",
      "|    Medical Incident|113794|\n",
      "|      Structure Fire| 23319|\n",
      "|              Alarms| 19406|\n",
      "|   Traffic Collision|  7013|\n",
      "|Citizen Assist / ...|  2524|\n",
      "|               Other|  2166|\n",
      "|        Outside Fire|  2094|\n",
      "|        Vehicle Fire|   854|\n",
      "|Gas Leak (Natural...|   764|\n",
      "|        Water Rescue|   755|\n",
      "|Odor (Strange / U...|   490|\n",
      "|   Electrical Hazard|   482|\n",
      "|Elevator / Escala...|   453|\n",
      "|Smoke Investigati...|   391|\n",
      "|          Fuel Spill|   193|\n",
      "|              HazMat|   124|\n",
      "|Industrial Accidents|    94|\n",
      "|           Explosion|    89|\n",
      "|Train / Rail Inci...|    57|\n",
      "|  Aircraft Emergency|    36|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "warning: one feature warning; for details, enable `:setting -feature' or `:replay -feature'\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.select(\"CallType\")\n",
    "    .where($\"CallType\".isNotNull)\n",
    "    .groupBy(\"CallType\")\n",
    "    .count()\n",
    "    .orderBy($\"count\" desc)\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "67d7f3cf-7a1a-47c9-802a-b061e178dfdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res170: Array[org.apache.spark.sql.Row] = Array([20110016,T13,2003235,Structure Fire,Other,2000 Block of CALIFORNIA ST,SF,94109,B04,38,3362,3,3,3,false,null,1,TRUCK,2,4,5,Pacific Heights,(37.7895840679362, -122.428071912459),020110016-T13,2.95,2002-01-11 00:00:00.0,2002-01-10 00:00:00.0,2002-01-11 01:51:44.0], [20110022,M17,2003241,Medical Incident,Other,0 Block of SILVERVIEW DR,SF,94124,B10,42,6495,3,3,3,true,null,1,MEDIC,1,10,10,Bayview Hunters Point,(37.7337623673897, -122.396113802632),020110022-M17,4.7,2002-01-11 00:00:00.0,2002-01-10 00:00:00.0,2002-01-11 03:01:18.0], [20110023,M41,2003242,Medical Incident,Other,MARKET ST/MCALLISTER ST,SF,94102,B03,1,1455,3,3,3,true,null,1,MEDIC,2,3,6,Tenderloin,(37.7811772186856, -122.411699931232),020110023-M41,2.4333334,2002-01-11 00:00:00.0,20...\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "76c8c886-755a-42ff-9265-572e8e4ab665",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Vamos a importar las funciones de agregacion llamándolas como F para que no haya conflictos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "43fe5fa2-74c5-4d3f-9fc0-2a4aa324442c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.{functions=>F}\n"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.{functions => F}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8c61b96e-7bec-4327-beea-4c238db24b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------------+--------------------------+-------------------------+\n",
      "|Numero de alarmas|Media de respuesta en mins|Respuesta + rapida en mins|Respuesta + lenta en mins|\n",
      "+-----------------+--------------------------+--------------------------+-------------------------+\n",
      "|           176170|         3.892364154521585|               0.016666668|                  1844.55|\n",
      "+-----------------+--------------------------+--------------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.select(F.sum($\"NumAlarms\").alias(\"Numero de alarmas\"),\n",
    "           F.avg($\"Tolay\").alias(\"Media de respuesta en mins\"),\n",
    "           F.min($\"Tolay\").alias(\"Respuesta + rapida en mins\"),\n",
    "           F.max($\"Tolay\").alias(\"Respuesta + lenta en mins\"),\n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11f96d7-9072-4505-a656-4dbbd454aaca",
   "metadata": {},
   "source": [
    "## Respuesta a las preguntas del libro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "4de5c647-dd11-41bd-b06d-6fea2af3f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "// usamos fire_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "be336d2d-b6a0-406d-8c2c-2c8b922db49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: integer (nullable = true)\n",
      " |-- Box: integer (nullable = true)\n",
      " |-- OriginalPriority: integer (nullable = true)\n",
      " |-- Priority: integer (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: integer (nullable = true)\n",
      " |-- SupervisorDistrict: integer (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "5fb462a3-939a-473e-a515-db79f383e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Pasamos las fechas de string a formato fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "d54e6b2d-22c1-47da-b4c8-c09b50d96a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fire2: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fire2 = fire_df.withColumn(\"CallDateF\",to_timestamp($\"CallDate\",\"MM/dd/yyyy\")).drop(\"CallDate\")\n",
    "               .withColumn(\"WatchDateF\",to_timestamp($\"WatchDate\",\"MM/dd/yyyy\")).drop(\"WatchDate\")\n",
    "               .withColumn(\"AvailableDtTmF\",to_timestamp($\"AvailableDtTm\",\"MM/dd/yyyy hh:mm:ss a\")).drop(\"AvailableDtTm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e5481654-c606-44d6-a041-06173cb96016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fire3: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 27 more fields]\n"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fire3 = fire2.withColumn(\"Anio\",year($\"CallDateF\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "83375361-5738-431b-b099-1834ac0143e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: integer (nullable = true)\n",
      " |-- Box: integer (nullable = true)\n",
      " |-- OriginalPriority: integer (nullable = true)\n",
      " |-- Priority: integer (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: integer (nullable = true)\n",
      " |-- SupervisorDistrict: integer (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: float (nullable = true)\n",
      " |-- CallDateF: timestamp (nullable = true)\n",
      " |-- WatchDateF: timestamp (nullable = true)\n",
      " |-- AvailableDtTmF: timestamp (nullable = true)\n",
      " |-- Anio: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "3a86d1e8-8222-4954-9e7d-1bf0aa0a2d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            CallType|Anio|\n",
      "+--------------------+----+\n",
      "|Odor (Strange / U...|2008|\n",
      "|        Vehicle Fire|2008|\n",
      "|        Water Rescue|2008|\n",
      "|   Traffic Collision|2008|\n",
      "|Gas Leak (Natural...|2008|\n",
      "|           Explosion|2008|\n",
      "|        Outside Fire|2008|\n",
      "|          Fuel Spill|2008|\n",
      "|               Other|2008|\n",
      "|Train / Rail Inci...|2008|\n",
      "|Extrication / Ent...|2008|\n",
      "|   Electrical Hazard|2008|\n",
      "|Industrial Accidents|2008|\n",
      "|       Assist Police|2008|\n",
      "|              HazMat|2008|\n",
      "|Citizen Assist / ...|2008|\n",
      "|      Structure Fire|2008|\n",
      "|Elevator / Escala...|2008|\n",
      "|    Medical Incident|2008|\n",
      "|Watercraft in Dis...|2008|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire3.select(\"CallType\",\"Anio\")\n",
    "    .where($\"Anio\"===2008)\n",
    "    .distinct()\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "274d4212-ce91-4e8f-9b56-6e3085c219b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fire4: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 28 more fields]\n"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fire4 = fire3.withColumn(\"Mes\",month($\"CallDateF\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "01c92036-abca-4862-86a0-3f0268c84ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: integer (nullable = true)\n",
      " |-- Box: integer (nullable = true)\n",
      " |-- OriginalPriority: integer (nullable = true)\n",
      " |-- Priority: integer (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: integer (nullable = true)\n",
      " |-- SupervisorDistrict: integer (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: float (nullable = true)\n",
      " |-- CallDateF: timestamp (nullable = true)\n",
      " |-- WatchDateF: timestamp (nullable = true)\n",
      " |-- AvailableDtTmF: timestamp (nullable = true)\n",
      " |-- Anio: integer (nullable = true)\n",
      " |-- Mes: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "5da44189-0845-4bc3-ba2e-7aa8e14fed55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|Mes|count|\n",
      "+---+-----+\n",
      "| 12|  762|\n",
      "|  9|  713|\n",
      "|  8|  767|\n",
      "|  7|  741|\n",
      "| 10|  789|\n",
      "| 11|  738|\n",
      "|  1|  699|\n",
      "|  3|  712|\n",
      "|  5|  760|\n",
      "|  4|  728|\n",
      "|  2|  710|\n",
      "|  6|  750|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire4.select(\"Mes\",\"Anio\")\n",
    "    .where($\"Anio\"===2008)\n",
    "    .groupBy(\"Mes\")\n",
    "    .count()\n",
    "    .show(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "5d0fb564-d3b8-42e9-bb1b-753b14b41693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+--------------------+------------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------------+--------------------------+----------------------+------------------+------------------------------+-------------------------------------+-------------+---------+-------------------+-------------------+-------------------+----+---+-------------+-------------+\n",
      "|CallNumber|UnitID|IncidentNumber|CallType        |CallFinalDisposition|Address                       |City|Zipcode|Battalion|StationArea|Box |OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType      |UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|Neighborhood                  |Location                             |RowID        |Delay    |CallDateF          |WatchDateF         |AvailableDtTmF     |Anio|Mes|week_day_full|week_of_month|\n",
      "+----------+------+--------------+----------------+--------------------+------------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------------+--------------------------+----------------------+------------------+------------------------------+-------------------------------------+-------------+---------+-------------------+-------------------+-------------------+----+---+-------------+-------------+\n",
      "|20110016  |T13   |2003235       |Structure Fire  |Other               |2000 Block of CALIFORNIA ST   |SF  |94109  |B04      |38         |3362|3               |3       |3            |false  |null         |1        |TRUCK         |2                         |4                     |5                 |Pacific Heights               |(37.7895840679362, -122.428071912459)|020110016-T13|2.95     |2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 01:51:44|2002|1  |Friday       |Fri          |\n",
      "|20110022  |M17   |2003241       |Medical Incident|Other               |0 Block of SILVERVIEW DR      |SF  |94124  |B10      |42         |6495|3               |3       |3            |true   |null         |1        |MEDIC         |1                         |10                    |10                |Bayview Hunters Point         |(37.7337623673897, -122.396113802632)|020110022-M17|4.7      |2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 03:01:18|2002|1  |Friday       |Fri          |\n",
      "|20110023  |M41   |2003242       |Medical Incident|Other               |MARKET ST/MCALLISTER ST       |SF  |94102  |B03      |1          |1455|3               |3       |3            |true   |null         |1        |MEDIC         |2                         |3                     |6                 |Tenderloin                    |(37.7811772186856, -122.411699931232)|020110023-M41|2.4333334|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 02:39:50|2002|1  |Friday       |Fri          |\n",
      "|20110032  |E11   |2003250       |Vehicle Fire    |Other               |APPLETON AV/MISSION ST        |SF  |94110  |B06      |32         |5626|3               |3       |3            |false  |null         |1        |ENGINE        |1                         |6                     |9                 |Bernal Heights                |(37.7388432849018, -122.423948785199)|020110032-E11|1.5      |2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 04:16:46|2002|1  |Friday       |Fri          |\n",
      "|20110043  |B04   |2003259       |Alarms          |Other               |1400 Block of SUTTER ST       |SF  |94109  |B04      |3          |3223|3               |3       |3            |false  |null         |1        |CHIEF         |2                         |4                     |2                 |Western Addition              |(37.7872890372638, -122.424236212664)|020110043-B04|3.4833333|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 06:01:58|2002|1  |Friday       |Fri          |\n",
      "|20110072  |T08   |2003279       |Structure Fire  |Other               |BEALE ST/FOLSOM ST            |SF  |94105  |B03      |35         |2122|3               |3       |3            |false  |null         |1        |TRUCK         |2                         |3                     |6                 |Financial District/South Beach|(37.7886866619654, -122.392722833778)|020110072-T08|1.75     |2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 08:03:26|2002|1  |Friday       |Fri          |\n",
      "|20110125  |E33   |2003301       |Alarms          |Other               |0 Block of FARALLONES ST      |SF  |94112  |B09      |33         |8324|3               |3       |3            |false  |null         |1        |ENGINE        |2                         |9                     |11                |Oceanview/Merced/Ingleside    |(37.7140353531157, -122.454117149916)|020110125-E33|2.7166667|2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 09:46:44|2002|1  |Friday       |Fri          |\n",
      "|20110130  |E36   |2003304       |Alarms          |Other               |600 Block of POLK ST          |SF  |94102  |B02      |3          |3114|3               |3       |3            |false  |null         |1        |ENGINE        |1                         |2                     |6                 |Tenderloin                    |(37.7826266328595, -122.41915582123) |020110130-E36|1.7833333|2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 09:58:53|2002|1  |Friday       |Fri          |\n",
      "|20110197  |E05   |2003343       |Medical Incident|Other               |1500 Block of WEBSTER ST      |SF  |94115  |B04      |5          |3513|3               |3       |3            |false  |null         |1        |ENGINE        |1                         |4                     |5                 |Japantown                     |(37.784958590666, -122.431435274503) |020110197-E05|1.5166667|2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 12:06:57|2002|1  |Friday       |Fri          |\n",
      "|20110215  |E06   |2003348       |Medical Incident|Other               |DIAMOND ST/MARKET ST          |SF  |94114  |B05      |6          |5415|3               |3       |3            |false  |null         |1        |ENGINE        |1                         |5                     |8                 |Castro/Upper Market           |(37.7618954753708, -122.437298717721)|020110215-E06|2.7666667|2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 13:08:40|2002|1  |Friday       |Fri          |\n",
      "|20110274  |M07   |2003381       |Medical Incident|Other               |2700 Block of MISSION ST      |SF  |94110  |B06      |11         |5525|1               |1       |2            |true   |null         |1        |MEDIC         |1                         |6                     |9                 |Mission                       |(37.7530339738059, -122.418588598473)|020110274-M07|2.1833334|2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 15:31:02|2002|1  |Friday       |Fri          |\n",
      "|20110275  |T15   |2003382       |Structure Fire  |Other               |BRUNSWICK ST/GUTTENBERG ST    |SF  |94112  |B09      |43         |6218|3               |3       |3            |false  |null         |1        |TRUCK         |1                         |9                     |11                |Excelsior                     |(37.7105545807996, -122.443335369545)|020110275-T15|2.5      |2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 14:59:04|2002|1  |Friday       |Fri          |\n",
      "|20110304  |E03   |2003399       |Medical Incident|Other               |1000 Block of SUTTER ST       |SF  |94109  |B04      |3          |1557|3               |3       |3            |false  |null         |1        |ENGINE        |1                         |4                     |3                 |Nob Hill                      |(37.7881263034393, -122.417657214041)|020110304-E03|2.4166667|2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 16:22:49|2002|1  |Friday       |Fri          |\n",
      "|20110308  |E14   |2003403       |Medical Incident|Other               |100 Block of 21ST AVE         |SF  |94121  |B07      |14         |7173|3               |3       |3            |false  |null         |1        |ENGINE        |1                         |7                     |1                 |Outer Richmond                |(37.7850084431077, -122.480723607753)|020110308-E14|4.95     |2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 16:18:33|2002|1  |Friday       |Fri          |\n",
      "|20110313  |B10   |2003408       |Structure Fire  |Other               |700 Block of CAPP ST          |SF  |94110  |B06      |7          |5472|3               |3       |3            |false  |null         |1        |CHIEF         |6                         |6                     |9                 |Mission                       |(37.7547064357942, -122.417513465479)|020110313-B10|1.4166666|2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 16:09:08|2002|1  |Friday       |Fri          |\n",
      "|20110313  |D3    |2003408       |Structure Fire  |Other               |700 Block of CAPP ST          |SF  |94110  |B06      |7          |5472|3               |3       |3            |false  |null         |1        |CHIEF         |4                         |6                     |9                 |Mission                       |(37.7547064357942, -122.417513465479)|020110313-D3 |2.5333333|2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 16:09:08|2002|1  |Friday       |Fri          |\n",
      "|20110313  |E32   |2003408       |Structure Fire  |Other               |700 Block of CAPP ST          |SF  |94110  |B06      |7          |5472|3               |3       |3            |true   |null         |1        |ENGINE        |8                         |6                     |9                 |Mission                       |(37.7547064357942, -122.417513465479)|020110313-E32|1.8833333|2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 16:09:08|2002|1  |Friday       |Fri          |\n",
      "|20110315  |RC2   |2003409       |Medical Incident|Other               |200 Block of LAGUNA HONDA BLVD|SF  |94116  |B08      |20         |8635|3               |3       |3            |true   |null         |1        |RESCUE CAPTAIN|2                         |8                     |7                 |West of Twin Peaks            |(37.7501117393668, -122.460819155469)|020110315-RC2|5.35     |2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 16:34:23|2002|1  |Friday       |Fri          |\n",
      "|20110330  |E14   |2003417       |Medical Incident|Other               |BALBOA ST/PARK PRESIDIO BL    |SF  |94118  |B07      |31         |7145|3               |3       |3            |false  |null         |1        |ENGINE        |1                         |7                     |1                 |Inner Richmond                |(37.7768682293368, -122.472039541478)|020110330-E14|2.0      |2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 16:51:31|2002|1  |Friday       |Fri          |\n",
      "|20110330  |M12   |2003417       |Medical Incident|Other               |BALBOA ST/PARK PRESIDIO BL    |SF  |94118  |B07      |31         |7145|3               |3       |3            |true   |null         |1        |MEDIC         |2                         |7                     |1                 |Inner Richmond                |(37.7768682293368, -122.472039541478)|020110330-M12|1.8166667|2002-01-11 00:00:00|2002-01-11 00:00:00|2002-01-11 16:51:12|2002|1  |Friday       |Fri          |\n",
      "+----------+------+--------------+----------------+--------------------+------------------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------------+--------------------------+----------------------+------------------+------------------------------+-------------------------------------+-------------+---------+-------------------+-------------------+-------------------+----+---+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire4.withColumn(\"week_day_full\", date_format(col(\"CallDateF\"), \"EEEE\"))\n",
    "    .withColumn(\"week_of_month\", date_format(col(\"CallDateF\"), \"E\")).show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "2b4b406e-84a0-45a4-8a4b-397104f639cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: integer (nullable = true)\n",
      " |-- Box: integer (nullable = true)\n",
      " |-- OriginalPriority: integer (nullable = true)\n",
      " |-- Priority: integer (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: integer (nullable = true)\n",
      " |-- SupervisorDistrict: integer (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: float (nullable = true)\n",
      " |-- CallDateF: timestamp (nullable = true)\n",
      " |-- WatchDateF: timestamp (nullable = true)\n",
      " |-- AvailableDtTmF: timestamp (nullable = true)\n",
      " |-- Anio: integer (nullable = true)\n",
      " |-- Mes: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "17b0295a-9211-43ff-8588-a9ecf990e451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----------------+\n",
      "|summary|          CallNumber|   IncidentNumber|\n",
      "+-------+--------------------+-----------------+\n",
      "|  count|              175296|           175296|\n",
      "|   mean|1.0023517638629518E8|9900785.635057274|\n",
      "| stddev|5.3969092834126316E7|5407019.524900525|\n",
      "|    min|             1030128|            30636|\n",
      "|    max|           183104004|         18130302|\n",
      "+-------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire4.select(\"CallNumber\",\"IncidentNumber\")\n",
    "    .describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "074a2e09-b763-4d6e-931a-70b98dbecc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cd73a6-460a-4018-ad0e-c85991e9221f",
   "metadata": {},
   "source": [
    "## Typed and UnTyped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "d26ae7af-f34e-492d-9e2b-6855d7f2a6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.Row\n"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "65315d20-1378-494c-ac3f-b872c579d640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row: org.apache.spark.sql.Row = [350,true,fnrieofj3r,null]\n"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val row = Row(350,true,\"fnrieofj3r\",null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "f070dcdf-f39e-4f3e-983c-faaff02d7cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res183: Int = 350\n"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.getInt(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "2286b54b-4296-4f57-85e4-619150585860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res184: Boolean = true\n"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.getBoolean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "d71db642-5bee-40b3-94ca-a5cb54cb3662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res185: String = fnrieofj3r\n"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.getString(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "9cd80ed0-008a-4786-bd7e-ed32dbe91753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res186: Any = null\n"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.get(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c39f9b8-f0a5-4739-9f36-e619a788c3b8",
   "metadata": {},
   "source": [
    "## Creando Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "e601584c-3079-4515-921f-798305d1979e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class DeviceIoTData\n"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class DeviceIoTData (battery_level: Long, c02_level: Long, \n",
    "                          cca2: String, cca3: String, cn: String,\n",
    "                          device_id: Long, device_name: String,\n",
    "                          humidity: Long, ip: String, latitude: Double,\n",
    "                          lcd: String, longitude: Double, scale:String,\n",
    "                          temp: Long, timestamp: Long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "060a3339-8e0c-445a-a59c-ae749fc75a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import spark.implicits._\n"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8026bb-a4f9-4fb5-b78d-12a262357022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "39c7aa5e-0bc1-4eed-ba64-7dea609d11a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ds: org.apache.spark.sql.Dataset[DeviceIoTData] = [battery_level: bigint, c02_level: bigint ... 13 more fields]\n"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ds = spark.read\n",
    "              .json(\"iot_devices.json\")\n",
    "              .as[DeviceIoTData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "93a58f97-66bc-4ba7-810a-cf65e5d2a049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+----+----+-------------+---------+---------------------+--------+-------------+--------+------+---------+-------+----+-------------+\n",
      "|battery_level|c02_level|cca2|cca3|cn           |device_id|device_name          |humidity|ip           |latitude|lcd   |longitude|scale  |temp|timestamp    |\n",
      "+-------------+---------+----+----+-------------+---------+---------------------+--------+-------------+--------+------+---------+-------+----+-------------+\n",
      "|8            |868      |US  |USA |United States|1        |meter-gauge-1xbYRYcj |51      |68.161.225.1 |38.0    |green |-97.0    |Celsius|34  |1458444054093|\n",
      "|7            |1473     |NO  |NOR |Norway       |2        |sensor-pad-2n2Pea    |70      |213.161.254.1|62.47   |red   |6.15     |Celsius|11  |1458444054119|\n",
      "|2            |1556     |IT  |ITA |Italy        |3        |device-mac-36TWSKiT  |44      |88.36.5.1    |42.83   |red   |12.83    |Celsius|19  |1458444054120|\n",
      "|6            |1080     |US  |USA |United States|4        |sensor-pad-4mzWkz    |32      |66.39.173.154|44.06   |yellow|-121.32  |Celsius|28  |1458444054121|\n",
      "|4            |931      |PH  |PHL |Philippines  |5        |therm-stick-5gimpUrBB|62      |203.82.41.9  |14.58   |green |120.97   |Celsius|25  |1458444054122|\n",
      "+-------------+---------+----+----+-------------+---------+---------------------+--------+-------------+--------+------+---------+-------+----+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.show(5,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "4488f237-dd68-49a8-99ee-026fa775cfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql._\n",
       "import org.apache.spark.sql.Dataset\n",
       "import org.apache.spark.sql.functions.{asc, col, desc}\n",
       "import org.apache.spark.sql.{functions=>F}\n"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.Dataset\n",
    "import org.apache.spark.sql.functions.{asc,col,desc}\n",
    "import org.apache.spark.sql.{functions => F}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "179afac1-772f-4d5a-8325-1aefce8bea38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ds2: org.apache.spark.sql.Dataset[DeviceIoTData] = [battery_level: bigint, c02_level: bigint ... 13 more fields]\n"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ds2 = ds.filter(d=>{d.temp>30 && d.humidity>70})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "f6aa76d1-1818-454e-ae73-abdcb197ff78",
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.SparkException",
     "evalue": " Job aborted due to stage failure: Task 0 in stage 209.0 failed 1 times, most recent failure: Lost task 0.0 in stage 209.0 (TID 396) (5fcc63a3e7cf executor driver): java.lang.ClassCastException: class $iw cannot be cast to class $iw ($iw is in unnamed module of loader org.apache.spark.repl.ExecutorClassLoader @14192ec4; $iw is in unnamed module of loader scala.tools.nsc.interpreter.IMain$TranslatingClassLoader @1f2963a5)",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 209.0 failed 1 times, most recent failure: Lost task 0.0 in stage 209.0 (TID 396) (5fcc63a3e7cf executor driver): java.lang.ClassCastException: class $iw cannot be cast to class $iw ($iw is in unnamed module of loader org.apache.spark.repl.ExecutorClassLoader @14192ec4; $iw is in unnamed module of loader scala.tools.nsc.interpreter.IMain$TranslatingClassLoader @1f2963a5)",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:349)",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)",
      "",
      "Driver stacktrace:",
      "  at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)",
      "  at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)",
      "  at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)",
      "  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)",
      "  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)",
      "  at scala.Option.foreach(Option.scala:407)",
      "  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)",
      "  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)",
      "  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:476)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:429)",
      "  at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:48)",
      "  at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3715)",
      "  at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2728)",
      "  at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)",
      "  at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)",
      "  at org.apache.spark.sql.Dataset.head(Dataset.scala:2728)",
      "  at org.apache.spark.sql.Dataset.take(Dataset.scala:2935)",
      "  at org.apache.spark.sql.Dataset.getRows(Dataset.scala:287)",
      "  at org.apache.spark.sql.Dataset.showString(Dataset.scala:326)",
      "  at org.apache.spark.sql.Dataset.show(Dataset.scala:808)",
      "  ... 77 elided",
      "Caused by: java.lang.ClassCastException: class $iw cannot be cast to class $iw ($iw is in unnamed module of loader org.apache.spark.repl.ExecutorClassLoader @14192ec4; $iw is in unnamed module of loader scala.tools.nsc.interpreter.IMain$TranslatingClassLoader @1f2963a5)",
      "  at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)",
      "  at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
      "  at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)",
      "  at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:349)",
      "  at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)",
      "  at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)",
      "  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
      "  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)",
      "  at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)",
      "  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)",
      "  at org.apache.spark.scheduler.Task.run(Task.scala:131)",
      "  at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)",
      "  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)",
      "  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)",
      "  at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)",
      "  at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)",
      "  ... 1 more",
      ""
     ]
    }
   ],
   "source": [
    "ds2.show(5,false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bd1126-ad99-4330-b718-ca76f6f3aa8c",
   "metadata": {},
   "source": [
    "### Otro ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c3c3c938-3ff9-46a0-8d6e-06282f9431af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class DeviceTempByCountry\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class DeviceTempByCountry(temp: Long, device_name: String, device_id: Long, cca3: String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ba3ea0ee-0469-4195-a118-96f6cbd23918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dsTemp: org.apache.spark.sql.Dataset[DeviceTempByCountry] = [temp: bigint, device_name: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dsTemp = ds.filter(d=>{d.temp>25})\n",
    "               .map(d => (d.temp,d.device_name,d.device_id,d.cca3))\n",
    "               .toDF(\"temp\",\"device_name\",\"device_id\",\"cca3\")\n",
    "               .as[DeviceTempByCountry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4b170907-c207-4231-b1e7-2d44d2c255a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.SparkException",
     "evalue": " Job aborted due to stage failure: Task 0 in stage 66.0 failed 1 times, most recent failure: Lost task 0.0 in stage 66.0 (TID 126) (5fcc63a3e7cf executor driver): java.lang.ClassCastException: class $iw cannot be cast to class $iw ($iw is in unnamed module of loader org.apache.spark.repl.ExecutorClassLoader @3fb6911f; $iw is in unnamed module of loader scala.tools.nsc.interpreter.IMain$TranslatingClassLoader @341ad6ac)",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 66.0 failed 1 times, most recent failure: Lost task 0.0 in stage 66.0 (TID 126) (5fcc63a3e7cf executor driver): java.lang.ClassCastException: class $iw cannot be cast to class $iw ($iw is in unnamed module of loader org.apache.spark.repl.ExecutorClassLoader @3fb6911f; $iw is in unnamed module of loader scala.tools.nsc.interpreter.IMain$TranslatingClassLoader @341ad6ac)",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:349)",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)",
      "",
      "Driver stacktrace:",
      "  at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)",
      "  at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)",
      "  at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)",
      "  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)",
      "  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)",
      "  at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)",
      "  at scala.Option.foreach(Option.scala:407)",
      "  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)",
      "  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)",
      "  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:476)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:429)",
      "  at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:48)",
      "  at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3715)",
      "  at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2728)",
      "  at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)",
      "  at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)",
      "  at org.apache.spark.sql.Dataset.head(Dataset.scala:2728)",
      "  at org.apache.spark.sql.Dataset.take(Dataset.scala:2935)",
      "  at org.apache.spark.sql.Dataset.getRows(Dataset.scala:287)",
      "  at org.apache.spark.sql.Dataset.showString(Dataset.scala:326)",
      "  at org.apache.spark.sql.Dataset.show(Dataset.scala:806)",
      "  at org.apache.spark.sql.Dataset.show(Dataset.scala:765)",
      "  ... 47 elided",
      "Caused by: java.lang.ClassCastException: class $iw cannot be cast to class $iw ($iw is in unnamed module of loader org.apache.spark.repl.ExecutorClassLoader @3fb6911f; $iw is in unnamed module of loader scala.tools.nsc.interpreter.IMain$TranslatingClassLoader @341ad6ac)",
      "  at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)",
      "  at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)",
      "  at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)",
      "  at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)",
      "  at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:349)",
      "  at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)",
      "  at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)",
      "  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)",
      "  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)",
      "  at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)",
      "  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)",
      "  at org.apache.spark.scheduler.Task.run(Task.scala:131)",
      "  at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)",
      "  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)",
      "  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)",
      "  at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)",
      "  at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)",
      "  ... 1 more",
      ""
     ]
    }
   ],
   "source": [
    "dsTemp.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3b4c95-dcda-498e-8edc-8723bbd66ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
