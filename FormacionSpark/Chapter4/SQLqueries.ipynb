{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16812410-fc73-456e-b93b-7e80a54a1a6e",
   "metadata": {},
   "source": [
    "# Capítulo 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "575e947b-7422-4dfd-b452-c729f81ea4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://5fcc63a3e7cf:4040\n",
       "SparkContext available as 'sc' (version = 3.2.1, master = local[*], app id = local-1655824783105)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "res0: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@637b15e9\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c19be54-e0d2-49c4-8e83-ebedba6c5931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: org.apache.spark.SparkContext = org.apache.spark.SparkContext@577835d0\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c29bf1-9c7e-4350-9afe-b6ea0ee13fb3",
   "metadata": {},
   "source": [
    "## Leer DataSet en una Vista Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0466a8f0-c252-482b-9043-ddf9a0850b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@637b15e9\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession\n",
    ".builder\n",
    ".appName(\"SparkSQLExampleApp\")\n",
    ".enableHiveSupport()\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4da047bf-9ec6-42d7-8cc5-fd0e6808e06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [date: int, delay: int ... 3 more fields]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"csv\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .load(\"departuredelays.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c39dd8-a484-4db2-9d63-9e2899d2fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Creacion de la vista temporal\n",
    "df.createOrReplaceTempView(\"tabla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "007c140f-060f-4986-a6cc-ee1852362fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "// También se podría haber inferido un squema, ddl\n",
    "// val schema = \"date STRING, delay INT, distance INT, origin STRING, destination STRING\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78327ae3-6a6d-4916-b82a-e3dd98d90f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: integer (nullable = true)\n",
      " |-- delay: integer (nullable = true)\n",
      " |-- distance: integer (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- destination: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c99a711-7732-4fa8-b91f-7d0b8dcaba3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------+------+-----------+\n",
      "|date   |delay|distance|origin|destination|\n",
      "+-------+-----+--------+------+-----------+\n",
      "|1011245|6    |602     |ABE   |ATL        |\n",
      "|1020600|-8   |369     |ABE   |DTW        |\n",
      "+-------+-----+--------+------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2,false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34238eea-57b4-4695-a074-3af03d05b8ce",
   "metadata": {},
   "source": [
    "The US flight delays data set has five columns:\n",
    "- The date column contains a string like 02190925. When converted, this maps to 02-19 09:25 am.\n",
    "- The delay column gives the delay in minutes between the scheduled and actual departure times. Early departures show negative numbers.\n",
    "- The distance column gives the distance in miles from the origin airport to the destination airport.\n",
    "- The origin column contains the origin IATA airport code.\n",
    "- The destination column contains the destination IATA airport code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d229bec2-ac32-4d5f-9145-96c82c782ab0",
   "metadata": {},
   "source": [
    "## Queries Básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c48f025-cd5b-41ae-96a1-ae17915349b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----------+\n",
      "|distance|origin|destination|\n",
      "+--------+------+-----------+\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "+--------+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Buscamos los vuelos con distancia > 1000\n",
    "spark.sql(\"\"\"select distance, origin, destination\n",
    "             from tabla\n",
    "             where distance > 1000\n",
    "             order by distance desc\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5ad857c-0ab9-4d80-b0be-8b5e284c5c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-----+\n",
      "|origin|destination|delay|\n",
      "+------+-----------+-----+\n",
      "|   SFO|        ORD| 1638|\n",
      "|   SFO|        ORD|  396|\n",
      "|   SFO|        ORD|  326|\n",
      "|   SFO|        ORD|  320|\n",
      "|   SFO|        ORD|  297|\n",
      "+------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Buscamos todos los vuelos entre San Francisco y Chicago\n",
    "spark.sql(\"\"\"select origin, destination, delay\n",
    "             from tabla\n",
    "             where origin = 'SFO' and destination = 'ORD' and delay > 120\n",
    "             order by delay desc\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b93fcee-4803-4847-8415-dd5df741d7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-----+----------------------------------+\n",
      "|origin|destination|delay|CAST(CAST(date AS STRING) AS DATE)|\n",
      "+------+-----------+-----+----------------------------------+\n",
      "|   ABE|        ATL|    6|                    +1011245-01-01|\n",
      "|   ABE|        DTW|   -8|                    +1020600-01-01|\n",
      "|   ABE|        ATL|   -2|                    +1021245-01-01|\n",
      "|   ABE|        ATL|   -4|                    +1020605-01-01|\n",
      "|   ABE|        ATL|   -4|                    +1031245-01-01|\n",
      "+------+-----------+-----+----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select origin, destination, delay, cast(cast(date as string) as date)\n",
    "             from tabla\n",
    "              \"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511d790c-aff3-4a5a-810f-0b5acdd304d7",
   "metadata": {},
   "source": [
    "## CASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40c60a5b-9cd6-440b-9e3f-ecb006846e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------+------+-----------+\n",
      "|   date|delay|distance|origin|destination|\n",
      "+-------+-----+--------+------+-----------+\n",
      "|1011245|    6|     602|   ABE|        ATL|\n",
      "|1020600|   -8|     369|   ABE|        DTW|\n",
      "+-------+-----+--------+------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select * from tabla\"\"\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4d6581-39a9-4ffc-b603-95eb2aff9eec",
   "metadata": {},
   "source": [
    "spark.sql(\"\"\"SELECT delay, origin, destination,\n",
    "CASE\n",
    "WHEN delay > 360 THEN 'Very Long Delays'\n",
    "WHEN delay > 120 AND delay < 360 THEN 'Long Delays'\n",
    "WHEN delay > 60 AND delay < 120 THEN 'Short Delays'\n",
    "WHEN delay > 0 and delay < 60 THEN 'Tolerable Delays'\n",
    "WHEN delay = 0 THEN 'No Delays'\n",
    "ELSE 'Early'\n",
    "END AS Flight_Delays\n",
    "FROM tabla ORDER BY origin, delay DESC\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b706331e-9bf5-49df-b063-279af18f3090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----------+------------+\n",
      "|delay|origin|destination|    retrasos|\n",
      "+-----+------+-----------+------------+\n",
      "|  333|   ABE|        ATL|Buen retraso|\n",
      "|  305|   ABE|        ATL|Buen retraso|\n",
      "|  275|   ABE|        ATL|Buen retraso|\n",
      "|  257|   ABE|        ATL|Buen retraso|\n",
      "|  247|   ABE|        ATL|Buen retraso|\n",
      "|  247|   ABE|        DTW|Buen retraso|\n",
      "|  219|   ABE|        ORD|Buen retraso|\n",
      "|  211|   ABE|        ATL|Buen retraso|\n",
      "|  197|   ABE|        DTW|Buen retraso|\n",
      "|  192|   ABE|        ORD|Buen retraso|\n",
      "+-----+------+-----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" select delay, origin, destination,\n",
    "                                                 CASE\n",
    "                                                     when delay > 360 then 'mucho retraso'\n",
    "                                                     when delay between 120 and 360 then 'Buen retraso'\n",
    "                                                     when delay between 60 and 120 then 'Algo de retraso'\n",
    "                                                     when delay between 0 and 60 then 'miniretraso'\n",
    "                                                     when delay == 0 then 'a tiempo'\n",
    "                                                     else 'pronto'\n",
    "\n",
    "                                                 END as retrasos\n",
    "             from tabla\n",
    "             order by origin, delay desc\"\"\")show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8050ca-7740-41eb-9cce-daab4fd0114a",
   "metadata": {},
   "source": [
    "## Crear DATABASE y TABLAS (managed & unmanaged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3473f79-0ab5-4652-a43d-2b4bce2e1c5b",
   "metadata": {},
   "source": [
    "### Crear database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7090df67-1a31-46c0-a620-6984b1c86628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create database learn_spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a0c9ed4-8f1c-4ceb-b6bb-d7f8dd07448e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res6: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"use learn_spark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9dd129-2afa-4eb3-bdc5-a7bceea7d09b",
   "metadata": {},
   "source": [
    "### Crear Managed Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a25a19a5-5e94-4112-8fa1-299a75e41fba",
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.sql.AnalysisException",
     "evalue": " Hive support is required to CREATE Hive TABLE (AS SELECT);",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.sql.AnalysisException: Hive support is required to CREATE Hive TABLE (AS SELECT);",
      "'CreateTable `learn_spark`.`tabla`, org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, ErrorIfExists",
      "",
      "  at org.apache.spark.sql.errors.QueryCompilationErrors$.ddlWithoutHiveSupportEnabledError(QueryCompilationErrors.scala:1270)",
      "  at org.apache.spark.sql.execution.datasources.HiveOnlyCheck$.$anonfun$apply$4(rules.scala:438)",
      "  at org.apache.spark.sql.execution.datasources.HiveOnlyCheck$.$anonfun$apply$4$adapted(rules.scala:435)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.foreach(TreeNode.scala:253)",
      "  at org.apache.spark.sql.execution.datasources.HiveOnlyCheck$.apply(rules.scala:435)",
      "  at org.apache.spark.sql.execution.datasources.HiveOnlyCheck$.apply(rules.scala:433)",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$37(CheckAnalysis.scala:550)",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$37$adapted(CheckAnalysis.scala:550)",
      "  at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)",
      "  at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)",
      "  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:550)",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:91)",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:182)",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:205)",
      "  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:202)",
      "  at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:88)",
      "  at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)",
      "  at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:196)",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)",
      "  at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:196)",
      "  at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:88)",
      "  at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:86)",
      "  at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:78)",
      "  at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:98)",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)",
      "  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)",
      "  at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)",
      "  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)",
      "  ... 39 elided",
      ""
     ]
    }
   ],
   "source": [
    "spark.sql(\"create table tabla(date string, delay int, distance int, origin string, destination string)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d973641-1a06-4aed-a91d-dede2e38a03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res25: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE TABLE tablaunmanaged3(date STRING, delay INT,\n",
    "distance INT, origin STRING, destination STRING)\n",
    "USING csv OPTIONS (PATH 'departuredelays.csv')\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0de285b-0a94-4bd9-b8f8-7f7c08eb5909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+--------+------+-----------+\n",
      "|date|delay|distance|origin|destination|\n",
      "+----+-----+--------+------+-----------+\n",
      "+----+-----+--------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select * \n",
    "from tablaunmanaged3\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6050535c-c092-498a-9f1c-d63d6c748f0e",
   "metadata": {},
   "source": [
    "## Creacion VISTAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5708f122-3c76-44c0-9dc0-8b7bfc183297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res29: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"create or replace temp view tempTabla as \n",
    "            select date, delay, origin, destination\n",
    "            from tabla\n",
    "            where origin = 'JFK'\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a5d8df4-09d6-42cd-900a-d51300c7475b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+-----------+\n",
      "|   date|delay|origin|destination|\n",
      "+-------+-----+------+-----------+\n",
      "|1010900|   14|   JFK|        LAX|\n",
      "|1011200|   -3|   JFK|        LAX|\n",
      "|1011900|    2|   JFK|        LAX|\n",
      "+-------+-----+------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select *\n",
    "            from tempTabla\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52987883-8428-4479-b1d9-729b68bbb115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res33: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"drop view if exists tempTabla\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95445501-745c-4ad6-84d5-36db45cb3f28",
   "metadata": {},
   "source": [
    "## Metadatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d651da0-ad2f-4b58-84f3-483f1ae0805f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------+-----------+\n",
      "|namespace  |tableName            |isTemporary|\n",
      "+-----------+---------------------+-----------+\n",
      "|learn_spark|tablaunmanaged       |false      |\n",
      "|learn_spark|tablaunmanaged2      |false      |\n",
      "|learn_spark|tablaunmanaged3      |false      |\n",
      "|learn_spark|unmanagedtablaejemplo|false      |\n",
      "|           |tabla                |true       |\n",
      "+-----------+---------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"show tables\"\"\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eaea4a01-458b-4427-b27e-922d999d7e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|  namespace|\n",
      "+-----------+\n",
      "|    default|\n",
      "|learn_spark|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2b9e6a04-0a93-48a4-9655-232b8af3feff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----------+\n",
      "|namespace|viewName|isTemporary|\n",
      "+---------+--------+-----------+\n",
      "|         |   tabla|       true|\n",
      "+---------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show views\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "401b737e-1389-4c53-b40d-071082603172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+--------------------+\n",
      "|       name|     description|         locationUri|\n",
      "+-----------+----------------+--------------------+\n",
      "|    default|default database|file:/home/jovyan...|\n",
      "|learn_spark|                |file:/home/jovyan...|\n",
      "+-----------+----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.catalog.listDatabases().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad9ef851-e334-4c54-a416-a7ecc618ac68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----------+---------+-----------+\n",
      "|                name|   database|description|tableType|isTemporary|\n",
      "+--------------------+-----------+-----------+---------+-----------+\n",
      "|      tablaunmanaged|learn_spark|       null| EXTERNAL|      false|\n",
      "|     tablaunmanaged2|learn_spark|       null| EXTERNAL|      false|\n",
      "|     tablaunmanaged3|learn_spark|       null| EXTERNAL|      false|\n",
      "|unmanagedtablaeje...|learn_spark|       null|  MANAGED|      false|\n",
      "|               tabla|       null|       null|TEMPORARY|       true|\n",
      "+--------------------+-----------+-----------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.catalog.listTables().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13ea327d-3341-4742-bfd3-19406ffc0eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------+--------+-----------+--------+\n",
      "|       name|description|dataType|nullable|isPartition|isBucket|\n",
      "+-----------+-----------+--------+--------+-----------+--------+\n",
      "|       date|       null|     int|    true|      false|   false|\n",
      "|      delay|       null|     int|    true|      false|   false|\n",
      "|   distance|       null|     int|    true|      false|   false|\n",
      "|     origin|       null|  string|    true|      false|   false|\n",
      "|destination|       null|  string|    true|      false|   false|\n",
      "+-----------+-----------+--------+--------+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.catalog.listColumns(\"tabla\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59370202-3e69-44f0-b177-19a83d086044",
   "metadata": {},
   "source": [
    "## Caching SQL tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51a3ec5a-049b-4952-943f-144b1e3532bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res54: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"cache table tabla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b26372ea-350d-44b6-9981-f1e908a633c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res55: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"uncache table tabla\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d296cc70-48e8-4cfd-a39e-994d21adee5b",
   "metadata": {},
   "source": [
    "## Pasar de tablas a DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "24df96f9-afdc-47d5-ae88-c0009218a7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tabladf: org.apache.spark.sql.DataFrame = [date: int, delay: int ... 3 more fields]\n"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tabladf = spark.sql(\"\"\"select * from tabla\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5276f44d-3faa-4f69-951c-c6230b692ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------+------+-----------+\n",
      "|   date|delay|distance|origin|destination|\n",
      "+-------+-----+--------+------+-----------+\n",
      "|1011245|    6|     602|   ABE|        ATL|\n",
      "|1020600|   -8|     369|   ABE|        DTW|\n",
      "+-------+-----+--------+------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabladf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa78b1-d3ba-4bb1-b532-df8ce11aa3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
