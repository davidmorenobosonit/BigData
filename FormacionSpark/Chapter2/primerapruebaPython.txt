C:\Users\antoniodavid.moreno>pyspark
Python 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)] on win32
Type "help", "copyright", "credits" or "license" for more information.
22/06/08 12:36:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
22/06/08 12:36:40 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 3.0.3
      /_/

Using Python version 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022 23:13:41)
SparkSession available as 'spark'.
>>> 22/06/08 12:36:54 WARN ProcfsMetricsGetter: Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
spark
<pyspark.sql.session.SparkSession object at 0x0000022018E17D60>
>>> strings = spark.read.text("C:/Spark3/README.md)
  File "<stdin>", line 1
    strings = spark.read.text("C:/Spark3/README.md)
                              ^
SyntaxError: unterminated string literal (detected at line 1)
>>> strings = spark.read.text("C:/Spark3/README.md")
>>> strings.show(10,truncate=False)
+--------------------------------------------------------------------------------+
|value                                                                           |
+--------------------------------------------------------------------------------+
|# Apache Spark                                                                  |
|                                                                                |
|Spark is a unified analytics engine for large-scale data processing. It provides|
|high-level APIs in Scala, Java, Python, and R, and an optimized engine that     |
|supports general computation graphs for data analysis. It also supports a       |
|rich set of higher-level tools including Spark SQL for SQL and DataFrames,      |
|MLlib for machine learning, GraphX for graph processing,                        |
|and Structured Streaming for stream processing.                                 |
|                                                                                |
|<https://spark.apache.org/>                                                     |
+--------------------------------------------------------------------------------+
only showing top 10 rows

>>> strings.count()
108

>>> strings = spark.read.text("../README.md")

>>> filtered = strings.filter(strings.value.contains("Spark"))

>>> filtered.count()
20

>>> exit()

C:\Users\antoniodavid.moreno>CORRECTO: el proceso con PID 16248 (proceso secundario de PID 4392)
ha sido terminado.
CORRECTO: el proceso con PID 4392 (proceso secundario de PID 17308)
ha sido terminado.
CORRECTO: el proceso con PID 17308 (proceso secundario de PID 21084)
ha sido terminado.